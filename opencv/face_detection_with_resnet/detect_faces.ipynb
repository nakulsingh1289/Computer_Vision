{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37664bit7fa94754980449c5b815f20e746f1f4d",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "import numpy as np\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[INFO] loading model...\nShape of image: (300, 300, 3)\nShape of blob: (1, 3, 300, 300)\n"
    }
   ],
   "source": [
    "# load our serialized model from disk\n",
    "\n",
    "print('[INFO] loading model...')\n",
    "net= cv2.dnn.readNetFromCaffe('deploy.prototxt','res10_300x300_ssd_iter_140000.caffemodel')\n",
    "\n",
    "# deply.prototxt defines the architecture of model\n",
    "# .caffemodel have the actual weights\n",
    "\n",
    "image= cv2.imread('data/img.jpg')\n",
    "image= cv2.resize(image, (300,300))\n",
    "(h,w,d )= image.shape\n",
    "print(\"Shape of image:\", image.shape)\n",
    "\n",
    "# calculating mean of RGB layers\n",
    "b_mean= np.mean(image[:,:,0])\n",
    "g_mean= np.mean(image[:,:,1])\n",
    "r_mean= np.mean(image[:,:,2])\n",
    "sub_mean= (b_mean, g_mean, r_mean)\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (300,300), sub_mean)\n",
    "print(\"Shape of blob:\", blob.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Help on built-in function blobFromImage:\n\nblobFromImage(...)\n    blobFromImage(image[, scalefactor[, size[, mean[, swapRB[, crop[, ddepth]]]]]]) -> retval\n    .   @brief Creates 4-dimensional blob from image. Optionally resizes and crops @p image from center,\n    .        *  subtract @p mean values, scales values by @p scalefactor, swap Blue and Red channels.\n    .        *  @param image input image (with 1-, 3- or 4-channels).\n    .        *  @param size spatial size for output image\n    .        *  @param mean scalar with mean values which are subtracted from channels. Values are intended\n    .        *  to be in (mean-R, mean-G, mean-B) order if @p image has BGR ordering and @p swapRB is true.\n    .        *  @param scalefactor multiplier for @p image values.\n    .        *  @param swapRB flag which indicates that swap first and last channels\n    .        *  in 3-channel image is necessary.\n    .        *  @param crop flag which indicates whether image will be cropped after resize or not\n    .        *  @param ddepth Depth of output blob. Choose CV_32F or CV_8U.\n    .        *  @details if @p crop is true, input image is resized so one side after resize is equal to corresponding\n    .        *  dimension in @p size and another one is equal or larger. Then, crop from the center is performed.\n    .        *  If @p crop is false, direct resize without cropping and preserving aspect ratio is performed.\n    .        *  @returns 4-dimensional Mat with NCHW dimensions order.\n\n"
    }
   ],
   "source": [
    "help(cv2.dnn.blobFromImage)\n",
    "\n",
    "# inshort blobFromImage takes care of all the preprocessing \n",
    "# creates a 4d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[INFO] computing object dectections...\n(1, 1, 200, 7)\n"
    }
   ],
   "source": [
    "# pass the blob through the network and obtain the detections # and predictions\n",
    "\n",
    "print('[INFO] computing object dectections...')\n",
    "net.setInput( blob )\n",
    "detections= net.forward()\n",
    "\n",
    "print(detections.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "-1"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loop over the detections \n",
    "\n",
    "for i in range (0, detections.shape[2]):\n",
    "    confidence = detections[0,0,i,2]\n",
    "    \n",
    "    if confidence > 0.5:\n",
    "        box= detections[0,0,i, 3:7]* np.array([w,h,w,h])\n",
    "        \n",
    "        (startX, startY, endX, endY)= box.astype('int')\n",
    "\n",
    "        text= '{:.2f}%'.format(confidence * 100)\n",
    "        y= startY -10 if startY - 10 > 10 else startY + 10\n",
    "\n",
    "        # draw rectangle\n",
    "        cv2.rectangle( image, (startX, startY), (endX, endY), (0,0,255), 2)\n",
    "        # put text \n",
    "        cv2.putText(image, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,0,255), 2)\n",
    "\n",
    "#show the output image\n",
    "\n",
    "cv2.imshow(\" Output\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}